{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bdf290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastf1 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fastf1 import get_session\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fastf1.Cache.enable_cache('E:\\School Stuff\\F1cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8521b6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcf03\\AppData\\Local\\Temp\\ipykernel_27560\\3134807600.py:1: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  new_features = pd.read_csv('new_features_output.csv')\n"
     ]
    }
   ],
   "source": [
    "new_features = pd.read_csv('new_features_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e778f047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'SessionTime', 'DriverAhead', 'DistanceToDriverAhead', 'Time',\n",
       "       'RPM', 'Speed', 'nGear', 'Throttle', 'Brake', 'DRS', 'Source',\n",
       "       'Distance', 'RelativeDistance', 'Status', 'X', 'Y', 'Z', 'Driver',\n",
       "       'LapNumber', 'TrackStatus', 'delta_time', 'delta_speed',\n",
       "       'delta_throttle', 'delta_brake', 'delta_rpm', 'delta_gear',\n",
       "       'acceleration', 'delta_dist_to_ahead', 'relative_speed_to_ahead',\n",
       "       'brake_mean_3', 'throttle_std_3', 'rpm_std_3', 'delta_x', 'delta_y',\n",
       "       'track_movement', 'TrackStatus_prev', 'SCin30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver_tel = new_features[new_features['Driver'] == 'VER']\n",
    "ver_tel = ver_tel.sort_values(by=['SessionTime']).copy()\n",
    "ver_tel = ver_tel.reset_index(drop=True)\n",
    "ver_tel.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e87584a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SessionTime</th>\n",
       "      <th>DriverAhead</th>\n",
       "      <th>DistanceToDriverAhead</th>\n",
       "      <th>Time</th>\n",
       "      <th>RPM</th>\n",
       "      <th>Speed</th>\n",
       "      <th>nGear</th>\n",
       "      <th>Throttle</th>\n",
       "      <th>Brake</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_dist_to_ahead</th>\n",
       "      <th>relative_speed_to_ahead</th>\n",
       "      <th>brake_mean_3</th>\n",
       "      <th>throttle_std_3</th>\n",
       "      <th>rpm_std_3</th>\n",
       "      <th>delta_x</th>\n",
       "      <th>delta_y</th>\n",
       "      <th>track_movement</th>\n",
       "      <th>TrackStatus_prev</th>\n",
       "      <th>SCin30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-05 17:03:22.842</td>\n",
       "      <td>0 days 01:02:22.839000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>8155.274983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-11-05 17:03:22.880</td>\n",
       "      <td>0 days 01:02:22.877000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0 days 00:00:00.038000</td>\n",
       "      <td>8160.183333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.182222</td>\n",
       "      <td>-1182.222222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.074773</td>\n",
       "      <td>1590.318312</td>\n",
       "      <td>25.933531</td>\n",
       "      <td>-101.835419</td>\n",
       "      <td>105.085682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-11-05 17:03:22.956</td>\n",
       "      <td>0 days 01:02:22.953000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0 days 00:00:00.114000</td>\n",
       "      <td>8170.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-229.379444</td>\n",
       "      <td>-38229.907407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.074773</td>\n",
       "      <td>1554.319894</td>\n",
       "      <td>9.035621</td>\n",
       "      <td>-35.608989</td>\n",
       "      <td>36.737482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-11-05 17:03:23.080</td>\n",
       "      <td>0 days 01:02:23.077000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0 days 00:00:00.238000</td>\n",
       "      <td>7892.550000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.516667</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-116.831111</td>\n",
       "      <td>-38943.703704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.776475</td>\n",
       "      <td>1792.064648</td>\n",
       "      <td>-17.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>68.154237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-11-05 17:03:23.196</td>\n",
       "      <td>0 days 01:02:23.193000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0 days 00:00:00.354000</td>\n",
       "      <td>7633.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-168.250556</td>\n",
       "      <td>-28041.759259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.497423</td>\n",
       "      <td>1921.954092</td>\n",
       "      <td>-7.585029</td>\n",
       "      <td>30.278897</td>\n",
       "      <td>31.214488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date             SessionTime  DriverAhead  \\\n",
       "0  2023-11-05 17:03:22.842  0 days 01:02:22.839000          NaN   \n",
       "1  2023-11-05 17:03:22.880  0 days 01:02:22.877000          NaN   \n",
       "2  2023-11-05 17:03:22.956  0 days 01:02:22.953000          NaN   \n",
       "3  2023-11-05 17:03:23.080  0 days 01:02:23.077000          NaN   \n",
       "4  2023-11-05 17:03:23.196  0 days 01:02:23.193000          3.0   \n",
       "\n",
       "   DistanceToDriverAhead                    Time          RPM  Speed  nGear  \\\n",
       "0                   0.53         0 days 00:00:00  8155.274983    0.0      1   \n",
       "1                   0.53  0 days 00:00:00.038000  8160.183333    0.0      1   \n",
       "2                   0.53  0 days 00:00:00.114000  8170.000000    0.0      1   \n",
       "3                   0.53  0 days 00:00:00.238000  7892.550000    0.0      1   \n",
       "4                   0.53  0 days 00:00:00.354000  7633.000000    0.0      1   \n",
       "\n",
       "    Throttle  Brake  ...  delta_dist_to_ahead relative_speed_to_ahead  \\\n",
       "0  15.000000  False  ...                  NaN                     NaN   \n",
       "1  15.000000  False  ...            -1.182222            -1182.222222   \n",
       "2  15.000000  False  ...          -229.379444           -38229.907407   \n",
       "3  15.516667  False  ...          -116.831111           -38943.703704   \n",
       "4  16.000000  False  ...          -168.250556           -28041.759259   \n",
       "\n",
       "   brake_mean_3  throttle_std_3    rpm_std_3    delta_x     delta_y  \\\n",
       "0           0.0             NaN          NaN        NaN         NaN   \n",
       "1           0.0       49.074773  1590.318312  25.933531 -101.835419   \n",
       "2           0.0       49.074773  1554.319894   9.035621  -35.608989   \n",
       "3           0.0       48.776475  1792.064648 -17.000000   66.000000   \n",
       "4           0.0       48.497423  1921.954092  -7.585029   30.278897   \n",
       "\n",
       "   track_movement TrackStatus_prev  SCin30  \n",
       "0             NaN              NaN     1.0  \n",
       "1      105.085682              1.0     1.0  \n",
       "2       36.737482              1.0     1.0  \n",
       "3       68.154237              1.0     1.0  \n",
       "4       31.214488              1.0     1.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel_spgp_2023 = new_features[new_features['Driver'] == 'HAM']\n",
    "tel_spgp_2023 = tel_spgp_2023.sort_values(by=['SessionTime']).copy()\n",
    "tel_spgp_2023 = tel_spgp_2023.reset_index(drop=True)\n",
    "tel_spgp_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbbad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NaNs\n",
    "nan_counts = ver_tel.isnull().sum()\n",
    "print(\"NaN counts by column:\")\n",
    "print(nan_counts[nan_counts > 0])  # Only show columns with NaNs\n",
    "\n",
    "# For infinities (both positive and negative)\n",
    "inf_counts = ver_tel.select_dtypes(include=[np.number]).apply(lambda x: np.isinf(x).sum())\n",
    "print(\"\\nInfinity counts by column:\")\n",
    "print(inf_counts[inf_counts > 0])  # Only show columns with infinities\n",
    "\n",
    "# Combined check for all problematic values\n",
    "print(\"\\nCombined problematic values:\")\n",
    "for col in ver_tel.columns:\n",
    "    if ver_tel[col].dtype in ['float64', 'float32', 'int64', 'int32']:\n",
    "        nan_count = ver_tel[col].isnull().sum()\n",
    "        inf_count = np.isinf(ver_tel[col]).sum()\n",
    "        if nan_count > 0 or inf_count > 0:\n",
    "            print(f\"{col}: {nan_count} NaNs, {inf_count} infinities\")\n",
    "\n",
    "# Or as a more compact one-liner for each type:\n",
    "print(\"\\nNaN summary:\")\n",
    "print(ver_tel.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nInfinity summary:\")\n",
    "print(ver_tel.select_dtypes(include=[np.number]).apply(lambda x: np.isinf(x).sum()).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['RPM', 'Speed', 'nGear', 'Throttle', 'Brake', 'X', 'Y', 'Z', 'delta_time',\n",
    "                'delta_speed', 'delta_throttle', 'delta_brake', 'delta_rpm', 'delta_gear',\n",
    "       'acceleration', 'brake_mean_3', 'throttle_std_3', 'rpm_std_3', 'delta_x', 'delta_y', 'track_movement']\n",
    "\n",
    "#feature_cols = ['DistanceToDriverAhead', 'RPM', 'Speed', 'nGear', 'Throttle', 'Brake', 'X', 'Y', 'Z']\n",
    "\n",
    "target_col = ['SCin30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80e0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spgp2022 = pd.read_csv('spgp2022_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944efbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tel_2022 = spgp2022[spgp2022['Driver'] == 'VER']\n",
    "tel_2022 = tel_2022.sort_values(by=['SessionTime']).copy()\n",
    "tel_2022 = tel_2022.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e8650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_end_focused_sequences(df, feature_cols, target_col, sequence_length, prediction_horizon=30):\n",
    "    \"\"\"Use sequence to predict what happens AFTER the sequence\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - sequence_length - prediction_horizon + 1):\n",
    "        # Features: current sequence\n",
    "        seq_x = df.iloc[i:i+sequence_length][feature_cols].values\n",
    "        \n",
    "        # Target: what happens in the NEXT prediction_horizon timesteps\n",
    "        future_window = df.iloc[i+sequence_length:i+sequence_length+prediction_horizon][target_col]\n",
    "        seq_y = int(future_window.any())\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca86e67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on 2022 (more safety car events)\n",
    "X_train_seq, y_train_seq = create_end_focused_sequences(\n",
    "    tel_2022, feature_cols, 'SCin30', \n",
    "    sequence_length=100, prediction_horizon=30\n",
    ")\n",
    "\n",
    "# Test on 2023 (fewer safety car events) \n",
    "X_test_seq, y_test_seq = create_end_focused_sequences(\n",
    "    tel_spgp_2023, feature_cols, 'SCin30',\n",
    "    sequence_length=100, prediction_horizon=30\n",
    ")\n",
    "\n",
    "print(f\"Training (2022): {np.bincount(y_train_seq)}\")\n",
    "print(f\"Testing (2023): {np.bincount(y_test_seq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f306f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = X_train_seq.astype(np.float32)\n",
    "y_train_seq = y_train_seq.astype(np.float32)\n",
    "X_test_seq = X_test_seq.astype(np.float32)\n",
    "y_test_seq = y_test_seq.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_seq = np.nan_to_num(X_train_seq, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "X_test_seq = np.nan_to_num(X_test_seq, nan=0.0, posinf=1e6, neginf=-1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddfb22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Flatten X to 2D (combine sequences and time steps)\n",
    "num_sequences, seq_len, num_features = X_train_seq.shape\n",
    "X_train_flat = X_train_seq.reshape(-1, num_features)  # shape: (42692 * 30, 24)\n",
    "\n",
    "# Fit and transform\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
    "\n",
    "# Reshape back to (42692, 30, 24)\n",
    "X_train_scaled = X_train_scaled_flat.reshape(num_sequences, seq_len, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e832fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sequences_test, seq_len_test, num_features_test = X_test_seq.shape\n",
    "X_test_flat = X_test_seq.reshape(-1, num_features_test)  # shape: (42692 * 30, 24)\n",
    "\n",
    "# Fit and transform\n",
    "X_test_scaled_flat = scaler.fit_transform(X_test_flat)\n",
    "\n",
    "# Reshape back to (42692, 30, 24)\n",
    "X_test_scaled = X_test_scaled_flat.reshape(num_sequences_test, seq_len_test, num_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab733c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TelemetrySequenceDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)  # Use long for classification if output is class ID\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Example usage\n",
    "train_dataset = TelemetrySequenceDataset(X_train_scaled, y_train_seq)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47270be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GRUClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout=0.2):\n",
    "        super(GRUClassifier, self).__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        #self.sigmoid = nn.Sigmoid()  # For binary classification ##NEED TO REMOVE\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]  # take last time step\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8361e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRUClassifier(input_dim=21, hidden_dim=64, num_layers=2, output_dim=1)\n",
    "pos_weight = torch.tensor([44279 / 509])\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 50  # Train longer but without early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Save model every 10 epochs to monitor progress\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea9a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    precision_recall_curve, roc_curve, auc,\n",
    "    precision_score, recall_score, f1_score, accuracy_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab61f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = loaded_model(torch.tensor(X_test_scaled, dtype=torch.float32))\n",
    "    probs = torch.sigmoid(logits).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c7ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple threshold analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"THRESHOLD ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Thresh\\tPrec\\tRecall\\tF1\\tAcc\\tTP\\tFP\\tFN\\tTN\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "best_f1 = 0\n",
    "best_threshold = 0.5\n",
    "\n",
    "for threshold in np.arange(0.1, 0.9, 0.1):\n",
    "    pred_binary = (probs > threshold).astype(int)\n",
    "    \n",
    "    precision = precision_score(y_test_seq, pred_binary, zero_division=0)\n",
    "    recall = recall_score(y_test_seq, pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_test_seq, pred_binary, zero_division=0)\n",
    "    accuracy = accuracy_score(y_test_seq, pred_binary)\n",
    "    \n",
    "    # Confusion matrix components\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test_seq, pred_binary).ravel()\n",
    "    \n",
    "    print(f\"{threshold:.1f}\\t{precision:.3f}\\t{recall:.3f}\\t{f1:.3f}\\t{accuracy:.3f}\\t{tp}\\t{fp}\\t{fn}\\t{tn}\")\n",
    "    \n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest threshold: {best_threshold:.1f} (F1: {best_f1:.3f})\")\n",
    "\n",
    "# Detailed results with best threshold\n",
    "pred_binary_best = (probs > best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(classification_report(y_test_seq, pred_binary_best, \n",
    "                          target_names=['No Safety Car', 'Safety Car']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONFUSION MATRIX\")\n",
    "print(\"=\" * 60)\n",
    "cm = confusion_matrix(y_test_seq, pred_binary_best)\n",
    "print(f\"                 Predicted\")\n",
    "print(f\"                 No SC  Safety Car\")\n",
    "print(f\"Actual No SC     {cm[0,0]:5d}  {cm[0,1]:9d}\")\n",
    "print(f\"Actual Safety Car {cm[1,0]:4d}  {cm[1,1]:9d}\")\n",
    "\n",
    "# Key performance metrics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"KEY PERFORMANCE METRICS\")\n",
    "print(\"=\" * 60)\n",
    "# Safe ROC AUC calculation\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_test_seq, probs)\n",
    "    print(f\"ROC AUC Score:           {roc_auc:.4f}\")\n",
    "except:\n",
    "    print(\"ROC AUC Score:           Cannot calculate (insufficient data)\")\n",
    "    roc_auc = None\n",
    "\n",
    "# Safe PR AUC calculation\n",
    "try:\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_test_seq, probs)\n",
    "    # Only calculate if we have valid curve\n",
    "    if len(precision_vals) > 1 and len(recall_vals) > 1:\n",
    "        pr_auc = auc(recall_vals, precision_vals)\n",
    "        print(f\"Precision-Recall AUC:    {pr_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"Precision-Recall AUC:    Cannot calculate (insufficient variation)\")\n",
    "        pr_auc = None\n",
    "except:\n",
    "    print(\"Precision-Recall AUC:    Cannot calculate (error in curve)\")\n",
    "    pr_auc = None\n",
    "\n",
    "print(f\"Best F1 Score:           {best_f1:.4f}\")\n",
    "print(f\"Precision (Safety Cars): {precision_score(y_test_seq, pred_binary_best, zero_division=0):.4f}\")\n",
    "print(f\"Recall (Safety Cars):    {recall_score(y_test_seq, pred_binary_best, zero_division=0):.4f}\")\n",
    "print(f\"Overall Accuracy:        {accuracy_score(y_test_seq, pred_binary_best):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f791be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact metrics\n",
    "tp = np.sum((pred_binary_best == 1) & (y_test_seq == 1))\n",
    "fp = np.sum((pred_binary_best == 1) & (y_test_seq == 0))\n",
    "fn = np.sum((pred_binary_best == 0) & (y_test_seq == 1))\n",
    "\n",
    "print(f\"\\nBUSINESS IMPACT:\")\n",
    "print(f\"Safety Cars Caught:      {tp}/{len(y_test_seq[y_test_seq==1])} ({tp/len(y_test_seq[y_test_seq==1])*100:.1f}%)\")\n",
    "print(f\"False Alarms:            {fp}\")\n",
    "print(f\"Missed Safety Cars:      {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c211f2af",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Prediction Timeline\n",
    "axes[0,0].plot(probs, alpha=0.7, label='Predicted Probability')\n",
    "axes[0,0].plot(y_test_seq, alpha=0.7, label='Actual Safety Cars')\n",
    "axes[0,0].axhline(y=best_threshold, color='red', linestyle='--', label=f'Best Threshold ({best_threshold:.1f})')\n",
    "axes[0,0].set_title('Safety Car Predictions Over Time')\n",
    "axes[0,0].set_xlabel('Sequence Index')\n",
    "axes[0,0].set_ylabel('Probability')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True)\n",
    "\n",
    "# 2. ROC Curve (only if calculable)\n",
    "if roc_auc is not None:\n",
    "    try:\n",
    "        fpr, tpr, _ = roc_curve(y_test_seq, probs)\n",
    "        axes[0,1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
    "        axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        axes[0,1].set_xlim([0.0, 1.0])\n",
    "        axes[0,1].set_ylim([0.0, 1.05])\n",
    "        axes[0,1].set_xlabel('False Positive Rate')\n",
    "        axes[0,1].set_ylabel('True Positive Rate')\n",
    "        axes[0,1].set_title('ROC Curve')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True)\n",
    "    except:\n",
    "        axes[0,1].text(0.5, 0.5, 'ROC Curve\\nCannot be calculated', \n",
    "                      ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "        axes[0,1].set_title('ROC Curve')\n",
    "else:\n",
    "    axes[0,1].text(0.5, 0.5, 'ROC Curve\\nCannot be calculated', \n",
    "                  ha='center', va='center', transform=axes[0,1].transAxes)\n",
    "    axes[0,1].set_title('ROC Curve')\n",
    "\n",
    "# 3. Precision-Recall Curve (only if calculable)\n",
    "if pr_auc is not None:\n",
    "    try:\n",
    "        axes[1,0].plot(recall_vals, precision_vals, color='blue', lw=2, label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
    "        axes[1,0].axhline(y=len(y_test_seq[y_test_seq==1])/len(y_test_seq), color='red', linestyle='--', label='Baseline')\n",
    "        axes[1,0].set_xlabel('Recall')\n",
    "        axes[1,0].set_ylabel('Precision')\n",
    "        axes[1,0].set_title('Precision-Recall Curve')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True)\n",
    "    except:\n",
    "        axes[1,0].text(0.5, 0.5, 'PR Curve\\nCannot be calculated', \n",
    "                      ha='center', va='center', transform=axes[1,0].transAxes)\n",
    "        axes[1,0].set_title('Precision-Recall Curve')\n",
    "else:\n",
    "    axes[1,0].text(0.5, 0.5, 'PR Curve\\nCannot be calculated', \n",
    "                  ha='center', va='center', transform=axes[1,0].transAxes)\n",
    "    axes[1,0].set_title('Precision-Recall Curve')\n",
    "\n",
    "# 4. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Safety Car', 'Safety Car'],\n",
    "            yticklabels=['No Safety Car', 'Safety Car'],\n",
    "            ax=axes[1,1])\n",
    "axes[1,1].set_title('Confusion Matrix')\n",
    "axes[1,1].set_ylabel('Actual')\n",
    "axes[1,1].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Probability distribution analysis\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROBABILITY DISTRIBUTION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Mean probability:        {probs.mean():.4f}\")\n",
    "print(f\"Std probability:         {probs.std():.4f}\")\n",
    "print(f\"Max probability:         {probs.max():.4f}\")\n",
    "print(f\"Min probability:         {probs.min():.4f}\")\n",
    "print(f\"Predictions > 0.5:       {(probs > 0.5).sum()}\")\n",
    "print(f\"Predictions > 0.8:       {(probs > 0.8).sum()}\")\n",
    "print(f\"Predictions > 0.9:       {(probs > 0.9).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932e6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec5f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Save just the model weights (recommended)\n",
    "torch.save(model.state_dict(), 'f1_safety_car_model.pth')\n",
    "\n",
    "# Method 2: Save the entire model (alternative)\n",
    "torch.save(model, 'f1_safety_car_model_complete.pth')\n",
    "\n",
    "# Method 3: Save with additional metadata (best practice)\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'model_architecture': {\n",
    "        'input_dim': 21,\n",
    "        'hidden_dim': 64,\n",
    "        'num_layers': 2,\n",
    "        'output_dim': 1\n",
    "    },\n",
    "    'training_info': {\n",
    "        'epochs_trained': num_epochs,\n",
    "        'best_threshold': best_threshold,\n",
    "        'best_f1_score': best_f1,\n",
    "        'class_weight': 44279/509,\n",
    "        'sequence_length': 100,\n",
    "        'prediction_horizon': 30\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'precision': precision_score(y_test_seq, pred_binary_best, zero_division=0),\n",
    "        'recall': recall_score(y_test_seq, pred_binary_best, zero_division=0),\n",
    "        'f1_score': best_f1\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'f1_safety_car_model_checkpoint.pth')\n",
    "\n",
    "# Save your feature scaler if you used one\n",
    "if 'scaler' in locals():\n",
    "    joblib.dump(scaler, 'f1_feature_scaler.joblib')\n",
    "\n",
    "# Save feature column names for future reference\n",
    "feature_info = {\n",
    "    'feature_columns': feature_cols,\n",
    "    'target_column': 'SCin30',\n",
    "    'model_description': 'F1 Safety Car Prediction - 2022 training, 2023 test'\n",
    "}\n",
    "\n",
    "with open('f1_model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "def load_f1_model(checkpoint_path, model_class):\n",
    "    # Load with weights_only=False (since it's your own model)\n",
    "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "    \n",
    "    model = model_class(\n",
    "        input_dim=checkpoint['model_architecture']['input_dim'],\n",
    "        hidden_dim=checkpoint['model_architecture']['hidden_dim'],\n",
    "        num_layers=checkpoint['model_architecture']['num_layers'],\n",
    "        output_dim=checkpoint['model_architecture']['output_dim']\n",
    "    )\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "# Usage:\n",
    "loaded_model, model_info = load_f1_model('f1_safety_car_model_checkpoint.pth', GRUClassifier)\n",
    "\n",
    "# Load feature info\n",
    "with open('f1_model_info.pkl', 'rb') as f:\n",
    "    feature_info = pickle.load(f)\n",
    "\n",
    "# Load scaler if you used one\n",
    "# scaler = joblib.load('f1_feature_scaler.joblib')\n",
    "\n",
    "print(f\"Model loaded! Best threshold: {model_info['training_info']['best_threshold']}\")\n",
    "print(f\"Expected F1 score: {model_info['training_info']['best_f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc338cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = loaded_model(torch.tensor(X_test_scaled, dtype=torch.float32))\n",
    "    probs_new = torch.sigmoid(logits).squeeze().numpy()\n",
    "    \n",
    "# Step 5: Evaluate using the saved best threshold\n",
    "best_threshold = model_info['training_info']['best_threshold']\n",
    "pred_binary = (probs_new > best_threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_test_seq, pred_binary, zero_division=0)\n",
    "recall = recall_score(y_test_seq, pred_binary, zero_division=0)\n",
    "f1 = f1_score(y_test_seq, pred_binary, zero_division=0)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_seq, pred_binary)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nRESULTS FOR HAM:\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Negatives: {tn}\")\n",
    "\n",
    "if len(y_test_seq[y_test_seq==1]) > 0:\n",
    "    print(f\"Safety Cars Caught: {tp}/{len(y_test_seq[y_test_seq==1])} ({tp/len(y_test_seq[y_test_seq==1])*100:.1f}%)\")\n",
    "\n",
    "# Step 6: Visualize results\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(probs_new, alpha=0.7, label='Predicted Probability')\n",
    "plt.plot(y_test_seq, alpha=0.7, label='Actual Safety Cars')\n",
    "plt.axhline(y=best_threshold, color='red', linestyle='--', label=f'Threshold ({best_threshold:.1f})')\n",
    "plt.title(f'Safety Car Predictions: HAM - 2023 Sao Paolo')\n",
    "plt.xlabel('Sequence Index')\n",
    "plt.ylabel('Probability')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "# Confusion matrix heatmap\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Safety Car', 'Safety Car'],\n",
    "            yticklabels=['No Safety Car', 'Safety Car'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_race_with_predictions(df, X, y, feature_cols, model, best_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Plot race timeline including model predictions\n",
    "    \"\"\"\n",
    "    # Get model predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.tensor(X, dtype=torch.float32))\n",
    "        probs = torch.sigmoid(logits).squeeze().numpy()\n",
    "    \n",
    "    pred_binary = (probs > best_threshold).astype(int)\n",
    "    \n",
    "    fig, axes = plt.subplots(5, 1, figsize=(20, 20))\n",
    "    \n",
    "    race_timeline = np.arange(len(df))\n",
    "    sequence_timeline = np.arange(len(y))\n",
    "    \n",
    "    # 1. Raw safety car events\n",
    "    safety_car_raw = df['SCin30'].values\n",
    "    axes[0].plot(race_timeline, safety_car_raw, 'r-', linewidth=2, label='Actual Safety Car Events')\n",
    "    axes[0].fill_between(race_timeline, 0, safety_car_raw, alpha=0.3, color='red')\n",
    "    axes[0].set_title('Actual Safety Car Events (SCin30)')\n",
    "    axes[0].set_ylabel('Safety Car Event')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # 2. Model predictions (probabilities)\n",
    "    axes[1].plot(sequence_timeline, probs, 'b-', linewidth=2, label='Predicted Probability')\n",
    "    axes[1].axhline(y=best_threshold, color='orange', linestyle='--', linewidth=2, label=f'Threshold ({best_threshold})')\n",
    "    axes[1].fill_between(sequence_timeline, 0, probs, alpha=0.3, color='blue')\n",
    "    axes[1].set_title('Model Predictions (Probabilities)')\n",
    "    axes[1].set_ylabel('Probability')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # 3. Binary predictions vs actual labels\n",
    "    axes[2].plot(sequence_timeline, y, 'r-', linewidth=3, alpha=0.7, label='Actual Labels')\n",
    "    axes[2].plot(sequence_timeline, pred_binary, 'b-', linewidth=2, alpha=0.7, label='Predicted Labels')\n",
    "    axes[2].set_title('Actual vs Predicted Labels')\n",
    "    axes[2].set_ylabel('Label (1=Safety Car)')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    # 4. Prediction accuracy timeline\n",
    "    correct_predictions = (y == pred_binary).astype(int)\n",
    "    axes[3].plot(sequence_timeline, correct_predictions, 'g-', linewidth=2)\n",
    "    axes[3].fill_between(sequence_timeline, 0, correct_predictions, alpha=0.3, color='green')\n",
    "    axes[3].set_title('Prediction Accuracy Timeline (1=Correct, 0=Incorrect)')\n",
    "    axes[3].set_ylabel('Correct Prediction')\n",
    "    axes[3].grid(True)\n",
    "    \n",
    "    # 5. Key telemetry with predictions overlay\n",
    "    if 'Speed' in feature_cols:\n",
    "        speed_data = df['Speed'].values\n",
    "        axes[4].plot(race_timeline, speed_data, 'k-', alpha=0.6, linewidth=1, label='Speed')\n",
    "        \n",
    "        # Mark high-confidence predictions\n",
    "        high_conf_sequences = sequence_timeline[probs > 0.8]\n",
    "        for seq_idx in high_conf_sequences:\n",
    "            if seq_idx < len(race_timeline):\n",
    "                axes[4].axvline(x=seq_idx, color='red', alpha=0.5, linewidth=1)\n",
    "        \n",
    "        axes[4].set_title('Speed with High-Confidence Predictions (red lines)')\n",
    "        axes[4].set_xlabel('Race Timeline (Timesteps)')\n",
    "        axes[4].set_ylabel('Speed')\n",
    "        axes[4].legend()\n",
    "        axes[4].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage with model predictions\n",
    "plot_race_with_predictions(tel_spgp_2023, X_test_seq, y_test_seq, feature_cols, loaded_model, best_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca50e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
