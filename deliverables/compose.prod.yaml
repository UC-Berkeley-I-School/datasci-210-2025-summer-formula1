# Production Docker Compose with HTTPS support via Nginx
# This extends the base compose.yaml with SSL/TLS termination

services:
  # Nginx reverse proxy for SSL termination
  nginx:
    container_name: f1_nginx
    build:
      context: ./nginx
      dockerfile: Dockerfile
    ports:
      - "80:80"
      - "443:443"
    volumes:
      # SSL certificates
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
      # Custom nginx config
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - webapp
      - model_service
    restart: unless-stopped
    networks:
      - default

  # Certbot for SSL certificate management
  certbot:
    image: certbot/certbot
    container_name: f1_certbot
    volumes:
      - ./certbot/conf:/etc/letsencrypt
      - ./certbot/www:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"
    restart: unless-stopped

  # Database service
  db:
    image: f1-timescaledb:latest
    container_name: f1_db
    build:
      context: ./f1-prediction-system/database
      dockerfile: Dockerfile
    environment:
      POSTGRES_DB: f1_telemetry
      POSTGRES_USER: f1_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-f1_password}
    volumes:
      - f1_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U f1_user -d f1_telemetry"]
      interval: 5s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    # Don't expose ports publicly in production
    networks:
      - default

  # Model service
  model_service:
    container_name: f1_model_service
    build:
      context: ./f1-prediction-system/model_service
      dockerfile: Dockerfile
    environment:
      POSTGRES_DB: f1_telemetry
      POSTGRES_USER: f1_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-f1_password}
      POSTGRES_HOST: db
      POSTGRES_PORT: 5432
    depends_on:
      db:
        condition: service_healthy
    volumes:
      - ./f1-prediction-system/models:/app/models
    restart: unless-stopped
    # Don't expose ports publicly in production
    networks:
      - default

  # Web application
  webapp:
    container_name: f1_webapp
    build:
      context: ./f1-prediction-system/webapp
      dockerfile: Dockerfile
    environment:
      API_BASE_URL: http://f1_model_service:8000
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      GUNICORN_LOG_LEVEL: ${GUNICORN_LOG_LEVEL:-INFO}
    depends_on:
      - model_service
    restart: unless-stopped
    # Don't expose ports publicly in production
    networks:
      - default

volumes:
  f1_data:

networks:
  default:
    driver: bridge